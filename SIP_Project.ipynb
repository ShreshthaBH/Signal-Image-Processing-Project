{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1txoF83wHyuoba5Kju6A0IH0WXjJNIWpV"},"id":"PkAt692s0tZe","outputId":"f6742cb1-2a90-48e2-b14b-b52dd8d1c01b"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","# Load YOLO object detector and Haar Cascade face detector\n","net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n","face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n","\n","# Define classes for YOLO\n","classes = []\n","with open(\"coco.names\", \"r\") as f:\n","    classes = [line.strip() for line in f.readlines()]\n","\n","# Set threshold values for object and face detection\n","conf_threshold = 0.5\n","nms_threshold = 0.4\n","\n","# Start video capture\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","    # Read video frame\n","    ret, frame = cap.read()\n","    \n","    # Apply object detection using YOLO\n","    height, width, _ = frame.shape\n","    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n","    net.setInput(blob)\n","    output_layers_names = net.getUnconnectedOutLayersNames()\n","    layerOutputs = net.forward(output_layers_names)\n","    \n","    # Initialize bounding box, class IDs, and confidence values for detected objects\n","    boxes = []\n","    confidences = []\n","    class_ids = []\n","    \n","    for output in layerOutputs:\n","        for detection in output:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence \u003e conf_threshold:\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","                \n","                x = int(center_x - w/2)\n","                y = int(center_y - h/2)\n","                \n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","                class_ids.append(class_id)\n","    \n","    # Apply non-maximum suppression to remove redundant bounding boxes\n","    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n","    \n","    # Draw bounding boxes around detected objects and apply face detection\n","    for i in indices:\n","        i = i[0]\n","        box = boxes[i]\n","        x, y, w, h = box\n","        label = str(classes[class_ids[i]])\n","        if label == 'person':\n","            # Draw bounding box around person\n","            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","            \n","            # Apply face detection using Haar Cascade\n","            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n","            for (x_face, y_face, w_face, h_face) in faces:\n","                # Blur detected face\n","                face = frame[y_face:y_face+h_face, x_face:x_face+w_face]\n","                if face.shape[0] \u003e 0 and face.shape[1] \u003e 0:\n","                    face = cv2.GaussianBlur(face, (23, 23), 30)\n","                    frame[y_face:y_face+h_face, x_face:x_face+w_face] = face\n","\n","    # Show video frame\n","    cv2.imshow(\"Video\", frame)\n","\n","    # Press 'q' to quit\n","    if cv2.waitKey(1) == ord('q'):\n","     break\n","\n","# Release video capture and close window\n","cap.release()\n","cv2.destroyAllWindows()\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPmhZO++lo6HX8mbi4+6dGy","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}